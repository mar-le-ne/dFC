{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "import numpy as np\n",
    "from nilearn import plotting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import butter, filtfilt, iirfilter, freqs\n",
    "from scipy.signal import freqz\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import signal\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savefiles(mtx, title, filename, typ):\n",
    "    \n",
    "    if (typ == \"png\") or (typ == \"pngcsv\"):\n",
    "        # save img\n",
    "        plt.matshow(mtx)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        plt.savefig(filename+\".png\")\n",
    "        plt.close()\n",
    "\n",
    "    if (typ == \"csv\") or (typ == \"pngcsv\"):\n",
    "        # save csv\n",
    "        np.savetxt(filename+\".csv\", mtx , delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = \"AD\" # AD or CN\n",
    "\n",
    "# Get the list of all files and directories\n",
    "in_path = \"./inputs/\"+group+\"_proc_roi100/\"\n",
    "dir_list = os.listdir(in_path)\n",
    "\n",
    "FC_sum = np.zeros([100, 100])\n",
    "count = 0\n",
    "for patient in dir_list:\n",
    "\n",
    "    data_set = pd.read_csv(in_path+patient, header=None)\n",
    "\n",
    "    # get time series in array\n",
    "    time_series = np.array(data_set) # (140, 400)\n",
    "    time_series = time_series[:,:100] # (140, 100)\n",
    "\n",
    "    # parameters MRI\n",
    "    N_voxels = len(time_series[1,:]) #100\n",
    "    N_TR = len(time_series[:,1])# 140 # number of repetition times\n",
    "    TR = 3 # repetition time in seconds\n",
    "\n",
    "    # Sample rate and desired cutoff frequencies (in Hz).\n",
    "    fs = 1/TR\n",
    "    lowcut = 0.01\n",
    "    highcut = 0.08\n",
    "\n",
    "    # filter\n",
    "    order = 12\n",
    "    nyq = 0.5*fs\n",
    "    b, a = butter(order, [lowcut/nyq, highcut/nyq], btype='band')\n",
    "    w, h = freqz(b, a, fs=fs)\n",
    "\n",
    "\n",
    "    # remove 1st 3 values value\n",
    "    remov = 3\n",
    "    time_series_r = time_series[remov:,:]\n",
    "    N_TR = N_TR - remov\n",
    "\n",
    "    # time\n",
    "    t = np.linspace(0,(TR*N_TR)/60, N_TR-1) # min\n",
    "\n",
    "    time_series_filt = np.zeros([N_TR, N_voxels])\n",
    "\n",
    "    # normalization\n",
    "    for parcel in range(N_voxels):\n",
    "\n",
    "        time_series_p = (time_series_r[:, parcel]  - np.mean(time_series_r[:, parcel] ))/ np.std(time_series_r[:, parcel])\n",
    "        time_series_f = filtfilt(b, a, time_series_p)\n",
    "        time_series_filt[:,parcel] = time_series_f\n",
    "\n",
    "    #plt.plot(t, time_series_filt[:,1])\n",
    "    #plt.title(\"filtered signal - voxel 1\")\n",
    "    #plt.show()\n",
    "\n",
    "    tseries_corr = pd.DataFrame(time_series_filt).corr(method ='pearson')\n",
    "    FC_sum = FC_sum + (tseries_corr + 1)/ 2 # 100, 100\n",
    "\n",
    "    \"\"\"Dynamic connectivity analysis\"\"\"\n",
    "\n",
    "    # sliding timeâ€“window\n",
    "    # with width of L = 20 TR slid in steps of 1 TR) approach\n",
    "\n",
    "    L = 13 # 39s = 13*3 window width\n",
    "    F = N_TR # 137\n",
    "\n",
    "    # number of time windows\n",
    "    W = F - L + 1 # 128 time windows\n",
    "    \n",
    "    # calculate dFC over all regions for a finite window time\n",
    "    start_w = 0\n",
    "    t_window = []\n",
    "\n",
    "    S = dict()\n",
    "    CS = np.zeros([N_voxels, W]) # nodes, graphs\n",
    "\n",
    "    for window_step in range(W):\n",
    "\n",
    "        \"\"\" S \"\"\" # 100, 100\n",
    "        tseries_wind = pd.DataFrame(time_series_filt[start_w : start_w + L,:])\n",
    "        tseries_corr = tseries_wind.corr(method ='pearson')\n",
    "        tseries_simil = (tseries_corr + 1)/ 2 # 100, 100\n",
    "        S[window_step] = tseries_simil\n",
    "\n",
    "        \"\"\" connectivity strength \"\"\"\n",
    "\n",
    "        CS[:,window_step] = tseries_simil.sum(axis=1) # (100, 125)\n",
    "\n",
    "        start_w = start_w + 1\n",
    "\n",
    "    savefiles(tseries_simil, \"Last Window Simililarity Graph\", './outputs/S_last_window/'+group+'/S_'+str(count), \"png\")\n",
    "    savefiles(CS, \"Connectivity Strength\", './outputs/CS/'+group+'/CS_'+str(count), \"png\")\n",
    "\n",
    "    # correlation of connectivity strength\n",
    "    Ccs_df = pd.DataFrame(CS)\n",
    "    Ccs = Ccs_df.corr(method ='pearson') #(125, 125)\n",
    "    #Scs = (cs + 1)/ 2\n",
    "    \n",
    "    savefiles(Ccs, \"Correlation Connectivity Strength\", './outputs/Ccs_100_corr/'+group+'/Ccs_'+str(count), \"pngcsv\")\n",
    "    \n",
    "    count = count +1\n",
    "\n",
    "# go to matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC = FC_sum/count\n",
    "savefiles(FC, \"Functional Connectivity \"+group+\" Group Average\", './outputs/FC_'+group, \"pngcsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Average S according to Modularity \"\"\"\n",
    "# get states from \n",
    "\n",
    "out_path_mod = \"./outputs/modularity/\"\n",
    "Ci_all = np.array(pd.read_csv(out_path_mod+\"Ci_all_\"+group+\".csv\", header=None))\n",
    "Q_all = np.array(pd.read_csv(out_path_mod+\"Q_all_\"+group+\".csv\", header=None))\n",
    "\n",
    "count = 0\n",
    "state_count = 0\n",
    "for patient in dir_list:\n",
    "    max_Ci = max(Ci_all[:,count])\n",
    "\n",
    "    for m in (range(1,max_Ci+1)):\n",
    "        ind = [index for index, value in enumerate(Ci_all[:, count]) if value == m]\n",
    "        S_avg = np.zeros([100,100])\n",
    "        for i in ind:\n",
    "            S_avg = S_avg + S[i]\n",
    "        conect_state = S_avg/len(ind)\n",
    "\n",
    "        # save\n",
    "        savefiles(conect_state[state_count], \"State\", './outputs/connect_state/'+group+'/ST_'+str(state_count), \"csv\")\n",
    "        state_count = state_count +1\n",
    "        \n",
    "    count = count+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
